# CUDA æ¶æ„ä¸åŸç†æ·±å…¥è§£æ

> æ·±å…¥ç†è§£ GPU ç¡¬ä»¶æ¶æ„ã€CUDA æ‰§è¡Œæ¨¡å‹å’Œå†…å­˜å±‚æ¬¡ç»“æ„ï¼Œä¸ºæ€§èƒ½ä¼˜åŒ–æ‰“ä¸‹åšå®çš„ç†è®ºåŸºç¡€ã€‚

## ç›®å½•

1. [GPU ç¡¬ä»¶æ¶æ„](#1-gpu-ç¡¬ä»¶æ¶æ„)
2. [CUDA æ‰§è¡Œæ¨¡å‹ï¼ˆSIMTï¼‰](#2-cuda-æ‰§è¡Œæ¨¡å‹simt)
3. [å†…å­˜å±‚æ¬¡ç»“æ„](#3-å†…å­˜å±‚æ¬¡ç»“æ„)
4. [çº¿ç¨‹è°ƒåº¦ä¸å ç”¨ç‡](#4-çº¿ç¨‹è°ƒåº¦ä¸å ç”¨ç‡)
5. [è®¡ç®—èƒ½åŠ›æ¼”è¿›](#5-è®¡ç®—èƒ½åŠ›æ¼”è¿›)

---

## 1. GPU ç¡¬ä»¶æ¶æ„

### 1.1 GPU vs CPUï¼šæ¶æ„å¯¹æ¯”

#### CPU æ¶æ„ç‰¹ç‚¹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CPU (å»¶è¿Ÿä¼˜åŒ–)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”   â”‚
â”‚  â”‚Coreâ”‚  â”‚Coreâ”‚  â”‚Coreâ”‚  â”‚Coreâ”‚   â”‚  4-16 ä¸ªå¼ºå¤§çš„æ ¸å¿ƒ
â”‚  â”‚ â–ˆâ–ˆ â”‚  â”‚ â–ˆâ–ˆ â”‚  â”‚ â–ˆâ–ˆ â”‚  â”‚ â–ˆâ–ˆ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜   â”‚
â”‚                                     â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ å¤§é‡ Cache (MB)          â”‚  å¤§å®¹é‡ç¼“å­˜
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ å¤æ‚æ§åˆ¶é€»è¾‘             â”‚  åˆ†æ”¯é¢„æµ‹ã€ä¹±åºæ‰§è¡Œ
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CPU è®¾è®¡å“²å­¦**ï¼š
- **å»¶è¿Ÿä¼˜åŒ–**ï¼šè®©æ¯ä¸ªä»»åŠ¡å°½å¿«å®Œæˆ
- **å¼ºå¤§çš„å•æ ¸**ï¼šå¤æ‚çš„æ§åˆ¶é€»è¾‘ã€å¤§ç¼“å­˜ã€é«˜é¢‘ç‡
- **é€‚åˆåœºæ™¯**ï¼šä¸²è¡Œä»»åŠ¡ã€å¤æ‚é€»è¾‘ã€é¢‘ç¹åˆ†æ”¯

#### GPU æ¶æ„ç‰¹ç‚¹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              GPU (ååé‡ä¼˜åŒ–)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”â”Œâ”€â”€â”â”Œâ”€â”€â”â”Œâ”€â”€â”  â”Œâ”€â”€â”â”Œâ”€â”€â”â”Œâ”€â”€â”â”Œâ”€â”€â”  ...  â”Œâ”€â”€â”â”Œâ”€â”€â”  â”‚
â”‚  â”‚SMâ”‚â”‚SMâ”‚â”‚SMâ”‚â”‚SMâ”‚  â”‚SMâ”‚â”‚SMâ”‚â”‚SMâ”‚â”‚SMâ”‚       â”‚SMâ”‚â”‚SMâ”‚  â”‚  æ•°åä¸ª SM
â”‚  â””â”€â”€â”˜â””â”€â”€â”˜â””â”€â”€â”˜â””â”€â”€â”˜  â””â”€â”€â”˜â””â”€â”€â”˜â””â”€â”€â”˜â””â”€â”€â”˜       â””â”€â”€â”˜â””â”€â”€â”˜  â”‚  (Streaming
â”‚                                                        â”‚   Multiprocessor)
â”‚  æ¯ä¸ª SM åŒ…å«ï¼š                                         â”‚
â”‚  - 64-128 ä¸ª CUDA Core                                â”‚
â”‚  - å…±äº«å†…å­˜ (KB çº§)                                    â”‚
â”‚  - å¯„å­˜å™¨å †                                            â”‚
â”‚                                                        â”‚
â”‚  â–ˆâ–ˆ å°å®¹é‡ Cache                                       â”‚  ç®€å•ç¼“å­˜
â”‚  â–ˆ ç®€å•æ§åˆ¶é€»è¾‘                                        â”‚  SIMT æ‰§è¡Œ
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**GPU è®¾è®¡å“²å­¦**ï¼š
- **ååé‡ä¼˜åŒ–**ï¼šåŒæ—¶å¤„ç†å¤§é‡ä»»åŠ¡
- **å¤§é‡ç®€å•æ ¸å¿ƒ**ï¼šæ•°åƒä¸ª CUDA Core
- **é€‚åˆåœºæ™¯**ï¼šå¤§è§„æ¨¡å¹¶è¡Œã€æ•°æ®å¹¶è¡Œã€è®¡ç®—å¯†é›†

#### æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹

| æŒ‡æ ‡ | CPU (å…¸å‹) | GPU (å…¸å‹) | å€æ•° |
|------|-----------|-----------|------|
| æ ¸å¿ƒæ•° | 8-16 | 2000-10000 | **100-1000x** |
| å†…å­˜å¸¦å®½ | 50-100 GB/s | 500-1000 GB/s | **10x** |
| å³°å€¼ FLOPS | 500 GFLOPS | 20-40 TFLOPS | **40-80x** |
| Cache å¤§å° | 8-32 MB | 1-6 MB | 0.1x |
| åŠŸè€— | 65-125W | 150-350W | 2-3x |

**å…³é”®æ´å¯Ÿ**ï¼š
- GPU ç”¨**ç”µæ™¶ä½“é¢„ç®—**æ¢å–**å¹¶è¡Œåº¦**ï¼Œè€Œéå•æ ¸æ€§èƒ½
- é€‚åˆ**è®¡ç®—å¯†é›†å‹**ä»»åŠ¡ï¼Œè€Œé**å»¶è¿Ÿæ•æ„Ÿå‹**ä»»åŠ¡

---

### 1.2 SM (Streaming Multiprocessor) æ¶æ„

SM æ˜¯ GPU çš„æ ¸å¿ƒè®¡ç®—å•å…ƒï¼Œæ¯ä¸ª GPU åŒ…å«æ•°åä¸ª SMã€‚

#### SM çš„ç»„æˆéƒ¨åˆ†ï¼ˆä»¥ Ampere æ¶æ„ä¸ºä¾‹ï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Streaming Multiprocessor (SM)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚         Warp Scheduler (4 ä¸ª)                â”‚     â”‚  æŒ‡ä»¤è°ƒåº¦
â”‚  â”‚  æ¯ä¸ªå‘¨æœŸå¯å‘å°„ 4 æ¡ç‹¬ç«‹æŒ‡ä»¤                  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   CUDA Cores (FP32/INT32)                 â”‚       â”‚
â”‚  â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        â”‚  64ä¸ª â”‚  æµ®ç‚¹/æ•´æ•°è¿ç®—
â”‚  â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   Tensor Cores (æ··åˆç²¾åº¦çŸ©é˜µè¿ç®—)          â”‚       â”‚
â”‚  â”‚   â–ˆâ–ˆâ–ˆâ–ˆ                                     â”‚   4ä¸ª â”‚  AI åŠ é€Ÿ
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   Load/Store Units (LD/ST)                â”‚       â”‚
â”‚  â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         â”‚  32ä¸ª â”‚  å†…å­˜è®¿é—®
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   Special Function Units (SFU)            â”‚       â”‚
â”‚  â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 â”‚  16ä¸ª â”‚  è¶…è¶Šå‡½æ•°
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚  (sin/cos/sqrt)
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   Shared Memory / L1 Cache                â”‚       â”‚
â”‚  â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (128 KB)       â”‚       â”‚  å¯é…ç½®
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   Register File (å¯„å­˜å™¨å †)                â”‚       â”‚
â”‚  â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (256 KB)             â”‚       â”‚  65536 ä¸ª 32-bit
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### SM çš„å…³é”®å‚æ•°ï¼ˆä¸åŒæ¶æ„ï¼‰

| æ¶æ„ | SM æ•°é‡ | CUDA Cores/SM | Tensor Cores/SM | å¯„å­˜å™¨/SM | å…±äº«å†…å­˜/SM |
|------|---------|---------------|-----------------|-----------|-------------|
| **Kepler (K80)** | 13 | 192 | 0 | 64K | 48 KB |
| **Pascal (P100)** | 56 | 64 | 0 | 64K | 64 KB |
| **Volta (V100)** | 80 | 64 | 8 | 64K | 96 KB |
| **Turing (T4)** | 40 | 64 | 8 | 64K | 64 KB |
| **Ampere (A100)** | 108 | 64 | 4 | 64K | 164 KB |
| **Hopper (H100)** | 132 | 128 | 4 | 64K | 228 KB |

**æ³¨æ„**ï¼š
- ç°ä»£æ¶æ„ä¸­ï¼Œ**Tensor Core** æˆä¸º AI åŠ é€Ÿçš„å…³é”®
- **å¯„å­˜å™¨æ•°é‡**æ˜¯é™åˆ¶å¹¶å‘çº¿ç¨‹çš„é‡è¦å› ç´ 
- **å…±äº«å†…å­˜**è¶Šæ¥è¶Šå¤§ï¼Œæ¥è¿‘ L1 Cache å¤§å°

---

### 1.3 CUDA Core çš„å¾®æ¶æ„

```
å•ä¸ª CUDA Core ç»“æ„ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    CUDA Core         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  FP32 Unit     â”‚ â”‚  32-bit æµ®ç‚¹è¿ç®—å•å…ƒ
â”‚  â”‚  (+, -, *, /)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  INT32 Unit    â”‚ â”‚  32-bit æ•´æ•°è¿ç®—å•å…ƒ
â”‚  â”‚  (+, -, &, |)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ‰§è¡Œæ–¹å¼ï¼š
- æ¯ä¸ªå‘¨æœŸæ¯ä¸ª Core æ‰§è¡Œ 1 æ¡ FP32 æˆ– INT32 æŒ‡ä»¤
- 64 ä¸ª CUDA Core = æ¯å‘¨æœŸ 64 æ¡æŒ‡ä»¤ï¼ˆå¦‚æœå®Œå…¨åˆ©ç”¨ï¼‰
```

**å…³é”®å¯¹æ¯”**ï¼š
- **CPU Core**ï¼šä¹±åºæ‰§è¡Œã€åˆ†æ”¯é¢„æµ‹ã€å¤§é‡ç¼“å­˜ï¼Œå¤æ‚ä½†å¼ºå¤§
- **CUDA Core**ï¼šé¡ºåºæ‰§è¡Œã€ç®€å•æµæ°´çº¿ï¼Œç®€å•ä½†æ•°é‡å¤š

---

### 1.4 Tensor Core æ¶æ„ï¼ˆç°ä»£ GPUï¼‰

Tensor Core ä¸“ä¸º**çŸ©é˜µä¹˜æ³•**è®¾è®¡ï¼Œæ˜¯æ·±åº¦å­¦ä¹ åŠ é€Ÿçš„æ ¸å¿ƒã€‚

```
Tensor Core æ“ä½œï¼ˆä»¥ A100 ä¸ºä¾‹ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  D = A Ã— B + C  (çŸ©é˜µä¹˜åŠ è¿ç®—)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  è¾“å…¥ï¼š                                  â”‚
â”‚    A: 16Ã—16 çŸ©é˜µ (FP16/BF16/TF32/INT8)  â”‚
â”‚    B: 16Ã—16 çŸ©é˜µ                         â”‚
â”‚    C: 16Ã—16 çŸ©é˜µ (FP32 ç´¯åŠ å™¨)          â”‚
â”‚  è¾“å‡ºï¼š                                  â”‚
â”‚    D: 16Ã—16 çŸ©é˜µ (FP32)                 â”‚
â”‚                                         â”‚
â”‚  æ€§èƒ½ï¼š1 ä¸ª Tensor Core æ¯å‘¨æœŸå®Œæˆ      â”‚
â”‚        16Ã—16Ã—16 = 4096 æ¬¡ FMA æ“ä½œ     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ€§èƒ½ä¼˜åŠ¿**ï¼š
```
ä¼ ç»Ÿ CUDA Core:
  64 cores Ã— 2 FMA/cycle = 128 FP32 ops/cycle

Tensor Core (4ä¸ª):
  4 cores Ã— 4096 ops/cycle = 16384 FP16 ops/cycle
```

**åŠ é€Ÿæ¯”**ï¼š**100+ å€**ï¼ˆæ··åˆç²¾åº¦çŸ©é˜µè¿ç®—ï¼‰

**æ”¯æŒçš„æ•°æ®ç±»å‹**ï¼ˆAmpere/Hopperï¼‰ï¼š
- **FP64**ï¼šåŒç²¾åº¦ï¼ˆç§‘å­¦è®¡ç®—ï¼‰
- **TF32**ï¼š19-bit æµ®ç‚¹ï¼ˆæ·±åº¦å­¦ä¹ æ¨èï¼‰
- **FP16/BF16**ï¼šåŠç²¾åº¦ï¼ˆè®­ç»ƒåŠ é€Ÿï¼‰
- **INT8/INT4**ï¼šæ•´æ•°ï¼ˆæ¨ç†åŠ é€Ÿï¼‰

---

### 1.5 å®Œæ•´ GPU èŠ¯ç‰‡æ¶æ„

ä»¥ NVIDIA A100 ä¸ºä¾‹ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NVIDIA A100 GPU                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â” â”Œâ”€â”€â” â”Œâ”€â”€â” â”Œâ”€â”€â”    â”Œâ”€â”€â” â”Œâ”€â”€â” â”Œâ”€â”€â” â”Œâ”€â”€â”           â”‚
â”‚  â”‚SMâ”‚ â”‚SMâ”‚ â”‚SMâ”‚ â”‚SMâ”‚ ...â”‚SMâ”‚ â”‚SMâ”‚ â”‚SMâ”‚ â”‚SMâ”‚  (108 ä¸ª) â”‚
â”‚  â””â”€â”€â”˜ â””â”€â”€â”˜ â””â”€â”€â”˜ â””â”€â”€â”˜    â””â”€â”€â”˜ â””â”€â”€â”˜ â””â”€â”€â”˜ â””â”€â”€â”˜           â”‚
â”‚  â”Œâ”€â”€â” â”Œâ”€â”€â” â”Œâ”€â”€â” â”Œâ”€â”€â”    â”Œâ”€â”€â” â”Œâ”€â”€â” â”Œâ”€â”€â” â”Œâ”€â”€â”           â”‚
â”‚  â”‚SMâ”‚ â”‚SMâ”‚ â”‚SMâ”‚ â”‚SMâ”‚ ...â”‚SMâ”‚ â”‚SMâ”‚ â”‚SMâ”‚ â”‚SMâ”‚           â”‚
â”‚  â””â”€â”€â”˜ â””â”€â”€â”˜ â””â”€â”€â”˜ â””â”€â”€â”˜    â””â”€â”€â”˜ â””â”€â”€â”˜ â””â”€â”€â”˜ â””â”€â”€â”˜           â”‚
â”‚                                                            â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚                    L2 Cache (40 MB)                        â”‚  å…¨å±€å…±äº«
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ HBM2e  â”‚  â”‚ HBM2e  â”‚  â”‚ HBM2e  â”‚  â”‚ HBM2e  â”‚         â”‚  40/80 GB
â”‚  â”‚ Stack  â”‚  â”‚ Stack  â”‚  â”‚ Stack  â”‚  â”‚ Stack  â”‚         â”‚  HBM2e
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  (1555 GB/s)
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚         NVLink / PCIe Gen4                   â”‚        â”‚  äº’è¿
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å…³é”®å‚æ•°ï¼š
- 108 ä¸ª SM Ã— 64 CUDA Cores = 6912 ä¸ª CUDA Cores
- å³°å€¼æ€§èƒ½ï¼š19.5 TFLOPS (FP32) / 312 TFLOPS (FP16 Tensor Core)
- å†…å­˜å¸¦å®½ï¼š1555 GB/s (HBM2e)
- L2 Cacheï¼š40 MB
```

---

## 2. CUDA æ‰§è¡Œæ¨¡å‹ï¼ˆSIMTï¼‰

### 2.1 SIMT vs SIMD

CUDA ä½¿ç”¨ **SIMT** (Single Instruction, Multiple Threads) æ¨¡å‹ï¼Œä¸åŒäº CPU çš„ SIMDã€‚

#### SIMD (CPU)ï¼šå‘é‡åŒ–

```
CPU SIMD (ä¾‹å¦‚ AVX-512):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å•æ¡æŒ‡ä»¤æ“ä½œå‘é‡å¯„å­˜å™¨             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æŒ‡ä»¤ï¼šadd_ps  xmm0, xmm1          â”‚
â”‚                                    â”‚
â”‚  xmm0: [a0, a1, a2, a3]           â”‚
â”‚  xmm1: [b0, b1, b2, b3]           â”‚
â”‚  ç»“æœ: [a0+b0, a1+b1, a2+b2, ...]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç‰¹ç‚¹ï¼š
- æ˜¾å¼å‘é‡åŒ–ï¼ˆç¨‹åºå‘˜æˆ–ç¼–è¯‘å™¨å†³å®šï¼‰
- æ‰€æœ‰å…ƒç´ æ‰§è¡Œç›¸åŒæ“ä½œ
- æ— åˆ†æ”¯å‘æ•£æ¦‚å¿µ
```

#### SIMT (GPU)ï¼šçº¿ç¨‹æŸ

```
GPU SIMT (Warp):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  32 ä¸ªçº¿ç¨‹ç»„æˆ 1 ä¸ª Warp            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Thread 0:  c[0] = a[0] + b[0]    â”‚
â”‚  Thread 1:  c[1] = a[1] + b[1]    â”‚
â”‚  Thread 2:  c[2] = a[2] + b[2]    â”‚
â”‚  ...                               â”‚
â”‚  Thread 31: c[31] = a[31] + b[31] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç‰¹ç‚¹ï¼š
- éšå¼å¹¶è¡Œï¼ˆçœ‹èµ·æ¥åƒæ ‡é‡ä»£ç ï¼‰
- 32 ä¸ªçº¿ç¨‹é”æ­¥æ‰§è¡Œ
- æ”¯æŒåˆ†æ”¯ï¼ˆä½†æœ‰å‘æ•£æƒ©ç½šï¼‰
```

**SIMT çš„ä¼˜åŠ¿**ï¼š
1. **ç¼–ç¨‹ç®€å•**ï¼šå†™çš„æ˜¯æ ‡é‡ä»£ç ï¼Œæ‰§è¡Œæ˜¯å‘é‡åŒ–
2. **çµæ´»æ€§**ï¼šæ¯ä¸ªçº¿ç¨‹å¯ä»¥æœ‰ç‹¬ç«‹çš„æ•°æ®å’Œæ§åˆ¶æµ
3. **å¯æ‰©å±•**ï¼šåŒæ ·çš„ä»£ç å¯ä»¥åœ¨ä¸åŒ GPU ä¸Šè¿è¡Œ

---

### 2.2 Warpï¼šGPU çš„åŸºæœ¬æ‰§è¡Œå•ä½

#### Warp çš„å®šä¹‰

**Warp** æ˜¯ GPU è°ƒåº¦å’Œæ‰§è¡Œçš„æœ€å°å•ä½ï¼ŒåŒ…å« **32 ä¸ªçº¿ç¨‹**ï¼ˆå›ºå®šï¼‰ã€‚

```
Block åˆ° Warp çš„æ˜ å°„ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Thread Block (ä¾‹å¦‚ 256 ä¸ªçº¿ç¨‹)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Warp 0: Thread 0-31                   â”‚
â”‚  Warp 1: Thread 32-63                  â”‚
â”‚  Warp 2: Thread 64-95                  â”‚
â”‚  Warp 3: Thread 96-127                 â”‚
â”‚  Warp 4: Thread 128-159                â”‚
â”‚  Warp 5: Thread 160-191                â”‚
â”‚  Warp 6: Thread 192-223                â”‚
â”‚  Warp 7: Thread 224-255                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Warp æ•°é‡ = âŒˆBlock å¤§å° / 32âŒ‰
```

#### Warp çš„æ‰§è¡Œç‰¹æ€§

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Warp æ‰§è¡Œï¼ˆé”æ­¥åŒæ­¥ï¼‰                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Cycle 0:  æ‰€æœ‰ 32 ä¸ªçº¿ç¨‹æ‰§è¡ŒæŒ‡ä»¤ 1     â”‚
â”‚  Cycle 1:  æ‰€æœ‰ 32 ä¸ªçº¿ç¨‹æ‰§è¡ŒæŒ‡ä»¤ 2     â”‚
â”‚  Cycle 2:  æ‰€æœ‰ 32 ä¸ªçº¿ç¨‹æ‰§è¡ŒæŒ‡ä»¤ 3     â”‚
â”‚  ...                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å…³é”®è§„åˆ™**ï¼š
1. Warp å†…çš„çº¿ç¨‹**é”æ­¥æ‰§è¡Œ**ï¼ˆSIMTï¼‰
2. åŒä¸€ Warp çš„çº¿ç¨‹æ‰§è¡Œ**ç›¸åŒçš„æŒ‡ä»¤**ï¼ˆä½†å¯ä»¥æœ‰ä¸åŒçš„æ•°æ®ï¼‰
3. ä¸åŒ Warp **ç‹¬ç«‹è°ƒåº¦**ï¼Œå¯ä»¥æ‰§è¡Œä¸åŒçš„æŒ‡ä»¤

**ä¸ºä»€ä¹ˆæ˜¯ 32ï¼Ÿ**
- ç¡¬ä»¶è®¾è®¡æƒè¡¡ï¼šå¤ªå°æµªè´¹å¹¶è¡Œåº¦ï¼Œå¤ªå¤§å¢åŠ åˆ†æ”¯å‘æ•£
- ä¸å†…å­˜æ€»çº¿å®½åº¦ã€å¯„å­˜å™¨å †ç»“æ„åŒ¹é…
- å†å²å»¶ç»­ï¼ˆä» G80 æ¶æ„å¼€å§‹å°±æ˜¯ 32ï¼‰

---

### 2.3 åˆ†æ”¯å‘æ•£ï¼ˆBranch Divergenceï¼‰

åˆ†æ”¯å‘æ•£æ˜¯ SIMT æ¨¡å‹çš„**ä¸»è¦æ€§èƒ½é™·é˜±**ã€‚

#### é—®é¢˜ç¤ºä¾‹

```cuda
__global__ void divergentKernel(int *data, int n) {
    int tid = threadIdx.x + blockIdx.x * blockDim.x;

    if (tid % 2 == 0) {
        // åˆ†æ”¯ Aï¼šå¶æ•°çº¿ç¨‹
        data[tid] = data[tid] * 2;
    } else {
        // åˆ†æ”¯ Bï¼šå¥‡æ•°çº¿ç¨‹
        data[tid] = data[tid] + 1;
    }
}
```

#### ç¡¬ä»¶æ‰§è¡Œè¿‡ç¨‹

```
Warp 0 (Thread 0-31):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cycle 0-X:  è¯„ä¼°æ¡ä»¶ (tid % 2 == 0)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Thread  0: TRUE  â†’ æ‰§è¡Œåˆ†æ”¯ A              â”‚
â”‚  Thread  1: FALSE â†’ ç­‰å¾…ï¼ˆmask offï¼‰        â”‚
â”‚  Thread  2: TRUE  â†’ æ‰§è¡Œåˆ†æ”¯ A              â”‚
â”‚  Thread  3: FALSE â†’ ç­‰å¾…                     â”‚
â”‚  ...                                         â”‚
â”‚  Thread 30: TRUE  â†’ æ‰§è¡Œåˆ†æ”¯ A              â”‚
â”‚  Thread 31: FALSE â†’ ç­‰å¾…                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Cycle X+1: æ‰§è¡Œ data[tid] = data[tid] * 2  â”‚
â”‚            (åªæœ‰å¶æ•°çº¿ç¨‹æ´»è·ƒï¼Œå¥‡æ•°çº¿ç¨‹ç­‰å¾…)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Cycle X+2: æ‰§è¡Œ data[tid] = data[tid] + 1  â”‚
â”‚            (åªæœ‰å¥‡æ•°çº¿ç¨‹æ´»è·ƒï¼Œå¶æ•°çº¿ç¨‹ç­‰å¾…)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å®é™…æ‰§è¡Œæ—¶é—´ = åˆ†æ”¯ A æ—¶é—´ + åˆ†æ”¯ B æ—¶é—´
```

**æ€§èƒ½æŸå¤±**ï¼š
- **æ— åˆ†æ”¯å‘æ•£**ï¼š32 ä¸ªçº¿ç¨‹å…¨é€Ÿæ‰§è¡Œ
- **å®Œå…¨å‘æ•£**ï¼ˆæœ€åæƒ…å†µï¼‰ï¼šæ€§èƒ½é™ä½åˆ° **1/32**ï¼ˆ32 ä¸ªåˆ†æ”¯ï¼‰

#### é¿å…åˆ†æ”¯å‘æ•£çš„ç­–ç•¥

**ç­–ç•¥ 1ï¼šç¡®ä¿ Warp å†…ä¸€è‡´**
```cuda
// âŒ ä¸å¥½ï¼šWarp å†…å‘æ•£
if (tid % 2 == 0) { ... }

// âœ… å¥½ï¼šä»¥ Warp ä¸ºå•ä½åˆ†æ”¯
if ((tid / 32) % 2 == 0) {  // æ•´ä¸ª Warp èµ°åŒä¸€åˆ†æ”¯
    ...
}
```

**ç­–ç•¥ 2ï¼šä½¿ç”¨æ— åˆ†æ”¯ä»£ç **
```cuda
// âŒ åˆ†æ”¯ç‰ˆæœ¬
int result;
if (condition) {
    result = a;
} else {
    result = b;
}

// âœ… æ— åˆ†æ”¯ç‰ˆæœ¬ï¼ˆä½è¿ç®—/ä¸‰å…ƒè¿ç®—ç¬¦ï¼‰
int result = condition ? a : b;  // ç¼–è¯‘å™¨å¯èƒ½ä¼˜åŒ–ä¸º selp æŒ‡ä»¤
```

**ç­–ç•¥ 3ï¼šé‡æ–°ç»„ç»‡æ•°æ®**
```cuda
// å°†æ•°æ®æ’åºï¼Œä½¿ç›¸åŒç±»å‹çš„å…ƒç´ ç›¸é‚»
// ä¾‹å¦‚ï¼š[å¶æ•°1, å¶æ•°2, ..., å¥‡æ•°1, å¥‡æ•°2, ...]
// è¿™æ ·åŒä¸€ Warp çš„çº¿ç¨‹ä¼šæ‰§è¡Œç›¸åŒçš„åˆ†æ”¯
```

---

### 2.4 Warp è°ƒåº¦å™¨

æ¯ä¸ª SM åŒ…å«å¤šä¸ª **Warp è°ƒåº¦å™¨**ï¼ˆAmpere æ¶æ„ä¸­æœ‰ 4 ä¸ªï¼‰ã€‚

#### è°ƒåº¦å™¨çš„å·¥ä½œåŸç†

```
SM å†…çš„ Warp æ± ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SM å¯ä»¥åŒæ—¶é©»ç•™å¤šä¸ª Block             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Block 0:  Warp 0, Warp 1, ..., Warp 7â”‚  (8 ä¸ª Warp)
â”‚  Block 1:  Warp 8, Warp 9, ..., Warp 15â”‚
â”‚  Block 2:  Warp 16, Warp 17, ..., Warp 23â”‚
â”‚  ...                                   â”‚
â”‚  æ€»å…±ï¼šå¯èƒ½æœ‰ 32-64 ä¸ª Warp é©»ç•™       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ¯ä¸ªå‘¨æœŸï¼Œè°ƒåº¦å™¨ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. ä»å°±ç»ªçš„ Warp ä¸­é€‰æ‹© 4 ä¸ª          â”‚
â”‚  2. ä¸ºæ¯ä¸ª Warp å‘å°„ä¸€æ¡æŒ‡ä»¤           â”‚
â”‚  3. Warp å¯èƒ½å› ä¸ºä»¥ä¸‹åŸå› ä¸å°±ç»ªï¼š      â”‚
â”‚     - ç­‰å¾…å†…å­˜è®¿é—®                     â”‚
â”‚     - ç­‰å¾…åŒæ­¥ï¼ˆ__syncthreadsï¼‰       â”‚
â”‚     - æ‰§è¡Œé•¿å»¶è¿ŸæŒ‡ä»¤                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### å»¶è¿Ÿéšè—ï¼ˆLatency Hidingï¼‰

è¿™æ˜¯ GPU é«˜ååé‡çš„æ ¸å¿ƒæœºåˆ¶ï¼

```
æ—¶é—´çº¿ï¼ˆç®€åŒ–ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cycle 0:  Warp 0 å‘èµ·å†…å­˜è¯»å–ï¼ˆå»¶è¿Ÿ 400 å‘¨æœŸï¼‰   â”‚
â”‚  Cycle 1:  Warp 1 æ‰§è¡Œç®—æœ¯è¿ç®—                     â”‚
â”‚  Cycle 2:  Warp 2 æ‰§è¡Œç®—æœ¯è¿ç®—                     â”‚
â”‚  ...                                               â”‚
â”‚  Cycle 100: Warp 0 ä»åœ¨ç­‰å¾…                        â”‚
â”‚  ...                                               â”‚
â”‚  Cycle 400: Warp 0 æ•°æ®åˆ°è¾¾ï¼Œæ¢å¤æ‰§è¡Œ             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å…³é”®æ´å¯Ÿï¼š
- Warp 0 ç­‰å¾…æœŸé—´ï¼Œå…¶ä»– Warp ç»§ç»­æ‰§è¡Œ
- åªè¦æœ‰è¶³å¤Ÿçš„ Warpï¼ŒSM æ€»æœ‰äº‹å¯åš
- è¿™éœ€è¦è¶³å¤Ÿé«˜çš„"å ç”¨ç‡"ï¼ˆOccupancyï¼‰
```

**éœ€è¦å¤šå°‘ Warp æ‰å¤Ÿï¼Ÿ**
```
ç²—ç•¥ä¼°ç®—ï¼š
  å†…å­˜å»¶è¿Ÿ: ~400 å‘¨æœŸ
  æ¯å‘¨æœŸå¯å‘å°„: 4 æ¡æŒ‡ä»¤ï¼ˆ4 ä¸ªè°ƒåº¦å™¨ï¼‰
  éœ€è¦çš„ Warp: 400 / 4 = 100 ä¸ª Warpï¼ˆç†æƒ³å€¼ï¼‰

å®é™…ï¼š
  - ä¸€èˆ¬ 32-48 ä¸ªæ´»è·ƒ Warp å°±èƒ½è¾¾åˆ°è¾ƒå¥½çš„å»¶è¿Ÿéšè—
  - å–å†³äºè®¡ç®—å¼ºåº¦ï¼ˆcompute-intensive éœ€è¦æ›´å°‘ï¼‰
```

---

## 3. å†…å­˜å±‚æ¬¡ç»“æ„

### 3.1 å†…å­˜é‡‘å­—å¡”

```
                       å®¹é‡     å»¶è¿Ÿ        å¸¦å®½
                       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  å¯„å­˜å™¨ (Register)     256KB   1 cycle   >10TB/s   æœ€å¿«
       â–²
       â”‚
  L1 Cache /
  å…±äº«å†…å­˜ (Shared)     128KB   ~30 cycle  >8TB/s
       â–²
       â”‚
  L2 Cache (å…¨å±€)       40MB    ~200 cycle ~3TB/s
       â–²
       â”‚
  HBM (å…¨å±€å†…å­˜)        40GB    ~400 cycle 1.5TB/s
       â–²
       â”‚
  ä¸»æœºå†…å­˜ (Host RAM)   >64GB   ~10^5 cycle 25GB/s
       â–²
       â”‚
  ç£ç›˜ (Disk)          >1TB    ~10^7 cycle <1GB/s    æœ€æ…¢
```

**å…³é”®æ•°å­—å¯¹æ¯”**ï¼ˆA100ï¼‰ï¼š
| å†…å­˜ç±»å‹ | å®¹é‡ | å»¶è¿Ÿï¼ˆå‘¨æœŸï¼‰ | å¸¦å®½ | è®¿é—®ç²’åº¦ |
|---------|------|------------|------|---------|
| å¯„å­˜å™¨ | 256 KB/SM | 1 | ~19 TB/s | 4 bytes |
| å…±äº«å†…å­˜ | 164 KB/SM | ~20 | ~8 TB/s | 4/8/16 bytes |
| L1 Cache | åŒ…å«åœ¨å…±äº«å†…å­˜ | ~30 | ~8 TB/s | 128 bytes |
| L2 Cache | 40 MB | ~200 | ~3 TB/s | 128 bytes |
| HBM2e | 40/80 GB | ~400 | 1.55 TB/s | 32 bytes |
| PCIe 4.0 | Host RAM | ~50,000 | 25 GB/s | Variable |

**æ€§èƒ½å·®å¼‚**ï¼š
- å¯„å­˜å™¨ vs HBMï¼š**400 å€**å»¶è¿Ÿå·®å¼‚
- å…±äº«å†…å­˜ vs HBMï¼š**20 å€**å»¶è¿Ÿå·®å¼‚
- HBM vs Hostï¼š**60 å€**å¸¦å®½å·®å¼‚

---

### 3.2 å¯„å­˜å™¨ï¼ˆRegisterï¼‰

#### ç‰¹æ€§

```
æ¯ä¸ª SM çš„å¯„å­˜å™¨é…ç½®ï¼ˆAmpereï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Register File: 256 KB             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  = 65,536 ä¸ª 32-bit å¯„å­˜å™¨         â”‚
â”‚                                    â”‚
â”‚  åˆ†é…ç»™çº¿ç¨‹ï¼š                       â”‚
â”‚  - æ¯ä¸ªçº¿ç¨‹æœ€å¤š 255 ä¸ªå¯„å­˜å™¨       â”‚
â”‚  - åŠ¨æ€åˆ†é…ç»™æ´»è·ƒçº¿ç¨‹               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### å¯„å­˜å™¨é™åˆ¶å¯¹å ç”¨ç‡çš„å½±å“

```
ç¤ºä¾‹ï¼šå‡è®¾ SM æœ‰ 65,536 ä¸ªå¯„å­˜å™¨

Kernel ä½¿ç”¨ 64 ä¸ªå¯„å­˜å™¨/çº¿ç¨‹ï¼š
  æœ€å¤§çº¿ç¨‹æ•° = 65,536 / 64 = 1024 ä¸ªçº¿ç¨‹ âœ…

Kernel ä½¿ç”¨ 128 ä¸ªå¯„å­˜å™¨/çº¿ç¨‹ï¼š
  æœ€å¤§çº¿ç¨‹æ•° = 65,536 / 128 = 512 ä¸ªçº¿ç¨‹ âš ï¸ï¼ˆå ç”¨ç‡ä¸‹é™ï¼‰

Kernel ä½¿ç”¨ 256 ä¸ªå¯„å­˜å™¨/çº¿ç¨‹ï¼š
  æœ€å¤§çº¿ç¨‹æ•° = 65,536 / 256 = 256 ä¸ªçº¿ç¨‹ âŒï¼ˆå ç”¨ç‡ä¸¥é‡ä¸‹é™ï¼‰
```

**ä¼˜åŒ–å»ºè®®**ï¼š
```bash
# æŸ¥çœ‹å¯„å­˜å™¨ä½¿ç”¨
nvcc --ptxas-options=-v kernel.cu

# è¾“å‡ºç¤ºä¾‹ï¼š
# ptxas info    : Used 48 registers, 384 bytes smem

# é™åˆ¶å¯„å­˜å™¨æ•°é‡ï¼ˆå¯èƒ½é™ä½æ€§èƒ½ï¼‰
nvcc -maxrregcount=32 kernel.cu
```

#### å¯„å­˜å™¨æº¢å‡ºï¼ˆRegister Spillingï¼‰

```
å½“å¯„å­˜å™¨ä¸è¶³æ—¶ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç¼–è¯‘å™¨å°†å¯„å­˜å™¨"æº¢å‡º"åˆ°æœ¬åœ°å†…å­˜     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Local Memory (å®é™…æ˜¯å…¨å±€å†…å­˜)      â”‚
â”‚  - å»¶è¿Ÿï¼š~400 å‘¨æœŸ                 â”‚
â”‚  - ä¸¥é‡é™ä½æ€§èƒ½ï¼                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ£€æµ‹æº¢å‡º**ï¼š
```bash
nvcc --ptxas-options=-v kernel.cu
# æŸ¥æ‰¾ "lmem" (local memory)
# ptxas info    : Used 48 registers, 128 bytes lmem  â† å‘ç”Ÿæº¢å‡ºï¼
```

---

### 3.3 å…±äº«å†…å­˜ï¼ˆShared Memoryï¼‰

å…±äº«å†…å­˜æ˜¯ **Block å†…çº¿ç¨‹å…±äº«** çš„å¿«é€Ÿå†…å­˜ã€‚

#### æ¶æ„ç»†èŠ‚

```
å…±äº«å†…å­˜çš„ Bank ç»“æ„ï¼ˆ32 ä¸ª Bankï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Bank 0  Bank 1  Bank 2  ...  Bank 31      â”‚
â”‚  [0-3]   [4-7]   [8-11]       [124-127]    â”‚  æ¯ä¸ª Bank 4 å­—èŠ‚
â”‚  [128]   [132]   [136]        [252]        â”‚
â”‚  [256]   [260]   [264]        [380]        â”‚
â”‚  ...                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

åœ°å€åˆ° Bank çš„æ˜ å°„ï¼š
  Bank ID = (Address / 4) % 32
```

#### Bank Conflict

```
æ— å†²çªè®¿é—®ï¼ˆæœ€ä¼˜ï¼‰ï¼š
  Warp ä¸­ 32 ä¸ªçº¿ç¨‹è®¿é—® 32 ä¸ªä¸åŒçš„ Bank
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Thread 0 â†’ Bank 0               â”‚
  â”‚ Thread 1 â†’ Bank 1               â”‚  æ¯ä¸ª Bank ä¸€æ¬¡è®¿é—®
  â”‚ Thread 2 â†’ Bank 2               â”‚  = 1 ä¸ªå‘¨æœŸå®Œæˆ
  â”‚ ...                             â”‚
  â”‚ Thread 31 â†’ Bank 31             â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2-way Bank Conflictï¼š
  2 ä¸ªçº¿ç¨‹è®¿é—®åŒä¸€ Bank çš„ä¸åŒåœ°å€
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Thread 0, 1 â†’ Bank 0            â”‚  éœ€è¦ä¸²è¡ŒåŒ–
  â”‚ Thread 2, 3 â†’ Bank 1            â”‚  = 2 ä¸ªå‘¨æœŸå®Œæˆ
  â”‚ ...                             â”‚  æ€§èƒ½é™ä½ 2 å€
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

32-way Bank Conflictï¼ˆæœ€åï¼‰ï¼š
  æ‰€æœ‰çº¿ç¨‹è®¿é—®åŒä¸€ Bank
  = 32 ä¸ªå‘¨æœŸå®Œæˆ
  æ€§èƒ½é™ä½ 32 å€ï¼
```

#### é¿å… Bank Conflict

**ç¤ºä¾‹ 1ï¼šçŸ©é˜µè½¬ç½®**
```cuda
// âŒ æœ‰ Bank Conflict
__shared__ float tile[32][32];
tile[threadIdx.y][threadIdx.x] = input[...];  // å†™å…¥ï¼šæ— å†²çª
__syncthreads();
output[...] = tile[threadIdx.x][threadIdx.y]; // è¯»å–ï¼š32-way conflictï¼

// âœ… Padding é¿å…å†²çª
__shared__ float tile[32][33];  // å¤šä¸€åˆ—
// ç°åœ¨æ¯ä¸ª Bank çš„è®¿é—®æ¨¡å¼æ”¹å˜ï¼Œé¿å…å†²çª
```

**ç¤ºä¾‹ 2ï¼šè§„çº¦æ“ä½œ**
```cuda
// âœ… è¿ç»­è®¿é—®é¿å…å†²çª
__shared__ float sdata[256];
// è§„çº¦æ—¶æ­¥é•¿ä¸º 2 çš„å¹‚
for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
    if (tid < s) {
        sdata[tid] += sdata[tid + s];  // è¿ç»­è®¿é—®ï¼Œæ— å†²çª
    }
}
```

---

### 3.4 å…¨å±€å†…å­˜ï¼ˆGlobal Memoryï¼‰

#### åˆå¹¶è®¿å­˜ï¼ˆCoalesced Accessï¼‰

è¿™æ˜¯å…¨å±€å†…å­˜ä¼˜åŒ–çš„**æœ€é‡è¦**æ¦‚å¿µï¼

```
å†…å­˜äº‹åŠ¡ï¼ˆMemory Transactionï¼‰ï¼š
- æ¯æ¬¡è®¿é—®ä»¥ 32/64/128 å­—èŠ‚ä¸ºå•ä½
- Warp çš„å†…å­˜è®¿é—®ä¼šè¢«åˆå¹¶æˆå°½å¯èƒ½å°‘çš„äº‹åŠ¡

ç†æƒ³æƒ…å†µï¼ˆå®Œå…¨åˆå¹¶ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Thread 0:  è®¿é—®åœ°å€ 0x1000            â”‚
â”‚  Thread 1:  è®¿é—®åœ°å€ 0x1004            â”‚  è¿ç»­åœ°å€
â”‚  Thread 2:  è®¿é—®åœ°å€ 0x1008            â”‚  = 1 æ¬¡ 128B äº‹åŠ¡
â”‚  ...                                   â”‚
â”‚  Thread 31: è®¿é—®åœ°å€ 0x107C            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

éåˆå¹¶è®¿é—®ï¼ˆæœ€åæƒ…å†µï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Thread 0:  è®¿é—®åœ°å€ 0x1000            â”‚
â”‚  Thread 1:  è®¿é—®åœ°å€ 0x2000            â”‚  éšæœºåœ°å€
â”‚  Thread 2:  è®¿é—®åœ°å€ 0x3000            â”‚  = 32 æ¬¡ 32B äº‹åŠ¡
â”‚  ...                                   â”‚  å¸¦å®½åˆ©ç”¨ç‡ï¼š1/32
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ€§èƒ½å¯¹æ¯”**ï¼š
```cuda
// âœ… åˆå¹¶è®¿é—®
int tid = threadIdx.x + blockIdx.x * blockDim.x;
float val = data[tid];  // è¿ç»­è®¿é—®

// âŒ éåˆå¹¶è®¿é—®ï¼ˆè·¨æ­¥ï¼‰
int tid = threadIdx.x + blockIdx.x * blockDim.x;
float val = data[tid * stride];  // å¦‚æœ stride > 1ï¼Œéåˆå¹¶

// âŒ å®Œå…¨éšæœº
float val = data[randomIndex[tid]];  // æœ€åæƒ…å†µ
```

#### Cache Line å’Œå¯¹é½

```
L1/L2 Cache Lineï¼š128 å­—èŠ‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å¯¹é½è®¿é—®ï¼š                         â”‚
â”‚  åœ°å€ 0x0000-0x007F â†’ Cache Line 0 â”‚
â”‚  åœ°å€ 0x0080-0x00FF â†’ Cache Line 1 â”‚
â”‚  ...                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æœªå¯¹é½è®¿é—®çš„å½±å“ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è®¿é—® 0x0078-0x00F8 (128 å­—èŠ‚)     â”‚
â”‚  è·¨è¶Šä¸¤ä¸ª Cache Lineï¼             â”‚
â”‚  = 2 æ¬¡å†…å­˜äº‹åŠ¡ï¼ˆæ€§èƒ½é™ä½ï¼‰         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å¯¹é½å»ºè®®**ï¼š
- `cudaMalloc` è‡ªåŠ¨ 256 å­—èŠ‚å¯¹é½ âœ…
- æ‰‹åŠ¨åˆ†é…æ—¶ç¡®ä¿å¯¹é½ï¼š`__align__(128)`

---

### 3.5 å†…å­˜è®¿é—®æ¨¡å¼æ€»ç»“

| è®¿é—®æ¨¡å¼ | å¸¦å®½åˆ©ç”¨ç‡ | æ€§èƒ½ | ç¤ºä¾‹ |
|---------|-----------|------|------|
| **è¿ç»­å¯¹é½è®¿é—®** | 100% | â­â­â­â­â­ | `data[tid]` |
| **è¿ç»­æœªå¯¹é½** | ~80% | â­â­â­â­ | `data[tid + offset]` |
| **è·¨æ­¥è®¿é—® (stride=2)** | 50% | â­â­â­ | `data[tid * 2]` |
| **è·¨æ­¥è®¿é—® (stride=32)** | 3% | â­ | `data[tid * 32]` |
| **éšæœºè®¿é—®** | <5% | â˜† | `data[random[tid]]` |

---

## 4. çº¿ç¨‹è°ƒåº¦ä¸å ç”¨ç‡

### 4.1 å ç”¨ç‡ï¼ˆOccupancyï¼‰

**å®šä¹‰**ï¼šæ´»è·ƒ Warp æ•°é‡ / æœ€å¤§ Warp æ•°é‡

```
ç¤ºä¾‹è®¡ç®—ï¼ˆAmpere SMï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SM æœ€å¤§å¸¸é©»èµ„æºï¼š                  â”‚
â”‚  - æœ€å¤§ Warp æ•°ï¼š64                â”‚
â”‚  - æœ€å¤§çº¿ç¨‹æ•°ï¼š2048                â”‚
â”‚  - å¯„å­˜å™¨ï¼š65,536                  â”‚
â”‚  - å…±äº«å†…å­˜ï¼š164 KB                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Kernel é…ç½®ï¼š256 çº¿ç¨‹/Blockï¼Œä½¿ç”¨ 32 å¯„å­˜å™¨/çº¿ç¨‹
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ¯ä¸ª Blockï¼š                       â”‚
â”‚  - 8 ä¸ª Warp (256 / 32)            â”‚
â”‚  - 8192 ä¸ªå¯„å­˜å™¨ (256 Ã— 32)        â”‚
â”‚                                    â”‚
â”‚  SM å¯ä»¥é©»ç•™çš„ Block æ•°ï¼š           â”‚
â”‚  - æŒ‰ Warp é™åˆ¶ï¼š64 / 8 = 8 Blocks â”‚
â”‚  - æŒ‰å¯„å­˜å™¨é™åˆ¶ï¼š65536 / 8192 = 8  â”‚
â”‚  - å®é™…ï¼šmin(8, 8) = 8 Blocks     â”‚
â”‚                                    â”‚
â”‚  å ç”¨ç‡ï¼š(8 Ã— 8) / 64 = 100% âœ…    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 é™åˆ¶å› ç´ 

å ç”¨ç‡å—ä»¥ä¸‹å› ç´ é™åˆ¶ï¼ˆ**å–æœ€ä¸¥æ ¼çš„**ï¼‰ï¼š

```
1. å¯„å­˜å™¨ï¼ˆRegistersï¼‰
   æ¯çº¿ç¨‹å¯„å­˜å™¨æ•° Ã— çº¿ç¨‹æ•° â‰¤ 65,536

2. å…±äº«å†…å­˜ï¼ˆShared Memoryï¼‰
   æ¯ Block å…±äº«å†…å­˜ Ã— Block æ•° â‰¤ 164 KB

3. çº¿ç¨‹å—æ•°ï¼ˆBlocks per SMï¼‰
   ç¡¬ä»¶é™åˆ¶ï¼šæœ€å¤š 32 ä¸ª Block/SMï¼ˆAmpereï¼‰

4. Warp æ•°ï¼ˆWarpsï¼‰
   æœ€å¤š 64 ä¸ª Warp/SM

5. çº¿ç¨‹æ•°ï¼ˆThreadsï¼‰
   æœ€å¤š 2048 ä¸ªçº¿ç¨‹/SM
```

### 4.3 å ç”¨ç‡è®¡ç®—å·¥å…·

```bash
# æ–¹æ³• 1ï¼šç¼–è¯‘æ—¶æŸ¥çœ‹
nvcc --ptxas-options=-v kernel.cu

# æ–¹æ³• 2ï¼šCUDA Occupancy Calculatorï¼ˆExcelï¼‰
# NVIDIA å®˜æ–¹æä¾›ï¼š
# https://docs.nvidia.com/cuda/cuda-occupancy-calculator/

# æ–¹æ³• 3ï¼šä»£ç ä¸­æŸ¥è¯¢
int blockSize = 256;
int minGridSize, suggestedBlockSize;
cudaOccupancyMaxPotentialBlockSize(&minGridSize, &suggestedBlockSize,
                                   myKernel, 0, 0);
```

### 4.4 é«˜å ç”¨ç‡ä¸ä¸€å®šå¿«ï¼

**è¯¯åŒº**ï¼šå ç”¨ç‡è¶Šé«˜è¶Šå¥½

**çœŸç›¸**ï¼š
```
å ç”¨ç‡çš„ä½œç”¨ï¼šéšè—å»¶è¿Ÿ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è®¡ç®—å¯†é›†å‹ Kernelï¼š                â”‚
â”‚  - è®¡ç®—æ—¶é—´ >> å†…å­˜è®¿é—®æ—¶é—´         â”‚
â”‚  - ä½å ç”¨ç‡å³å¯ï¼ˆ30-50%ï¼‰          â”‚
â”‚  - æ›´å¤šå¯„å­˜å™¨åè€Œæ›´å¿«ï¼             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è®¿å­˜å¯†é›†å‹ Kernelï¼š                â”‚
â”‚  - å†…å­˜å»¶è¿Ÿéœ€è¦éšè—                â”‚
â”‚  - éœ€è¦é«˜å ç”¨ç‡ï¼ˆ75-100%ï¼‰         â”‚
â”‚  - æ›´å¤šæ´»è·ƒ Warp éšè—å»¶è¿Ÿ          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ¡ˆä¾‹**ï¼š
```cuda
// é«˜å¯„å­˜å™¨ä½¿ç”¨ï¼Œä½å ç”¨ç‡ï¼Œä½†å¯èƒ½æ›´å¿«
__global__ void compute_intensive(float *data, int n) {
    // ä½¿ç”¨ 128 ä¸ªå¯„å­˜å™¨/çº¿ç¨‹
    // å ç”¨ç‡ï¼š50%
    // ä½†æ¯ä¸ªçº¿ç¨‹æœ‰æ›´å¤šå¯„å­˜å™¨åšä¼˜åŒ–ï¼ŒILP æ›´é«˜
    float reg[32];  // å¯„å­˜å™¨æ•°ç»„
    // å¤æ‚è®¡ç®—...
}
```

---

## 5. è®¡ç®—èƒ½åŠ›æ¼”è¿›

### 5.1 ä¸»è¦æ¶æ„å¯¹æ¯”

| æ¶æ„ | å¹´ä»½ | è®¡ç®—èƒ½åŠ› | SM æ”¹è¿› | å†…å­˜ | å…³é”®ç‰¹æ€§ |
|------|-----|---------|---------|------|---------|
| **Fermi** | 2010 | 2.0-2.1 | 32 CUDA Cores/SM | GDDR5 | é¦–æ¬¡æ”¯æŒ ECCã€L1/L2 Cache |
| **Kepler** | 2012 | 3.0-3.7 | 192 Cores/SM | GDDR5 | åŠ¨æ€å¹¶è¡Œã€Hyper-Q |
| **Maxwell** | 2014 | 5.0-5.3 | 128 Cores/SM | GDDR5 | èƒ½æ•ˆæå‡ 2x |
| **Pascal** | 2016 | 6.0-6.2 | 64 Cores/SM | HBM2 | NVLinkã€ç»Ÿä¸€å†…å­˜ |
| **Volta** | 2017 | 7.0-7.2 | 64 Cores + 8 Tensor | HBM2 | **Tensor Core** é¦–æ¬¡ç™»åœº |
| **Turing** | 2018 | 7.5 | 64 Cores + 8 Tensor + RT | GDDR6 | **RT Core**ï¼ˆå…‰çº¿è¿½è¸ªï¼‰ |
| **Ampere** | 2020 | 8.0-8.6 | 64 Cores + 4 Tensor | HBM2e | FP64 Tensor Coreã€ç¨€ç–æ€§ |
| **Hopper** | 2022 | 9.0 | 128 Cores + 4 Tensor | HBM3 | **Transformer Engine**ã€DPX |
| **Ada Lovelace** | 2022 | 8.9 | DLSS 3ã€Shader æ‰§è¡Œé‡æ’ | GDDR6X | DLSS 3 å¸§ç”Ÿæˆ |
| **Blackwell** | 2024 | 10.0 | ä¸‹ä¸€ä»£ Tensor Core | HBM3e | é¢„è®¡ 2024-2025 |

### 5.2 Tensor Core æ¼”è¿›

| æ¶æ„ | Tensor Core ä»£ | æ”¯æŒç²¾åº¦ | æ€§èƒ½æå‡ | ä¸»è¦åº”ç”¨ |
|------|---------------|---------|---------|---------|
| **Volta** | ç¬¬ 1 ä»£ | FP16 | åŸºå‡† | æ·±åº¦å­¦ä¹ è®­ç»ƒ |
| **Turing** | ç¬¬ 2 ä»£ | FP16, INT8, INT4 | 2x | AI æ¨ç†åŠ é€Ÿ |
| **Ampere** | ç¬¬ 3 ä»£ | FP64, TF32, BF16, FP16, INT8 | 2x | ç§‘å­¦è®¡ç®— + AI |
| **Hopper** | ç¬¬ 4 ä»£ | FP8, FP16, INT8, TMA | 3x | å¤§æ¨¡å‹ï¼ˆTransformerï¼‰ |

**TF32ï¼ˆTensorFloat-32ï¼‰**ï¼š
- Ampere å¼•å…¥çš„æ–°æ ¼å¼
- ç²¾åº¦ï¼šFP32 çš„èŒƒå›´ï¼ŒFP16 çš„ç²¾åº¦
- æ— éœ€ä»£ç ä¿®æ”¹ï¼Œè‡ªåŠ¨ä½¿ç”¨
- æ·±åº¦å­¦ä¹ æ¨èç²¾åº¦

---

### 5.3 å…³é”®ç‰¹æ€§æ—¶é—´çº¿

```
2010 â”€ Fermi â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       â”‚
       â”œâ”€ ç»Ÿä¸€åœ°å€ç©ºé—´
       â”œâ”€ ECC å†…å­˜
       â””â”€ L1/L2 Cache

2012 â”€ Kepler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       â”‚
       â”œâ”€ åŠ¨æ€å¹¶è¡Œï¼ˆGPU å¯åŠ¨ GPUï¼‰
       â”œâ”€ Hyper-Qï¼ˆ32 ä¸ªç¡¬ä»¶é˜Ÿåˆ—ï¼‰
       â””â”€ GPUDirect RDMA

2016 â”€ Pascal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       â”‚
       â”œâ”€ NVLinkï¼ˆé«˜é€Ÿ GPU äº’è¿ï¼‰
       â”œâ”€ HBM2ï¼ˆé«˜å¸¦å®½å†…å­˜ï¼‰
       â””â”€ ç»Ÿä¸€å†…å­˜æ”¹è¿›

2017 â”€ Volta â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â† AI æ—¶ä»£å¼€å§‹
       â”‚
       â”œâ”€ â˜… Tensor Coreï¼ˆAI åŠ é€Ÿï¼‰
       â”œâ”€ ç‹¬ç«‹çº¿ç¨‹è°ƒåº¦
       â””â”€ å…±äº«å†…å­˜å®¹é‡ç¿»å€

2020 â”€ Ampere â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       â”‚
       â”œâ”€ TF32 ç²¾åº¦
       â”œâ”€ FP64 Tensor Coreï¼ˆç§‘å­¦è®¡ç®—ï¼‰
       â”œâ”€ å¤šå®ä¾‹ GPUï¼ˆMIGï¼‰
       â””â”€ ç»“æ„åŒ–ç¨€ç–æ€§ï¼ˆ2:4 ç¨€ç–ï¼‰

2022 â”€ Hopper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â† Transformer ä¼˜åŒ–
       â”‚
       â”œâ”€ Transformer Engineï¼ˆFP8ï¼‰
       â”œâ”€ çº¿ç¨‹å—é›†ç¾¤ï¼ˆThread Block Clusterï¼‰
       â”œâ”€ TMAï¼ˆTensor Memory Acceleratorï¼‰
       â””â”€ DPX æŒ‡ä»¤ï¼ˆåŠ¨æ€è§„åˆ’åŠ é€Ÿï¼‰
```

---

## æ€»ç»“ï¼šå…³é”®è¦ç‚¹

### ğŸ¯ ç¡¬ä»¶æ¶æ„æ ¸å¿ƒæ¦‚å¿µ

1. **SM æ˜¯åŸºæœ¬è®¡ç®—å•å…ƒ**
   - åŒ…å« CUDA Coreã€Tensor Coreã€å…±äº«å†…å­˜ã€å¯„å­˜å™¨
   - ä¸€ä¸ª GPU æœ‰æ•°åä¸ªåˆ°ä¸Šç™¾ä¸ª SM

2. **Warp æ˜¯æ‰§è¡Œå•ä½**
   - 32 ä¸ªçº¿ç¨‹é”æ­¥æ‰§è¡Œï¼ˆSIMTï¼‰
   - åˆ†æ”¯å‘æ•£æ˜¯æ€§èƒ½æ€æ‰‹

3. **å†…å­˜å±‚æ¬¡è‡³å…³é‡è¦**
   - å¯„å­˜å™¨ > å…±äº«å†…å­˜ > L2 > HBMï¼ˆé€Ÿåº¦é€’å‡ï¼‰
   - åˆå¹¶è®¿å­˜æ˜¯å…¨å±€å†…å­˜ä¼˜åŒ–çš„å…³é”®

4. **å ç”¨ç‡æ˜¯æ‰‹æ®µï¼Œä¸æ˜¯ç›®çš„**
   - ç”¨äºéšè—å†…å­˜å»¶è¿Ÿ
   - è®¡ç®—å¯†é›†å‹ä»»åŠ¡ä¸éœ€è¦ 100% å ç”¨ç‡

### ğŸ“š æ·±å…¥å­¦ä¹ èµ„æº

- [CUDA C++ Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)
- [GPU Architecture Whitepaper](https://www.nvidia.com/en-us/data-center/ampere-architecture/)
- [CUDA C++ Best Practices Guide](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/)

### ğŸ”— ç›¸å…³æ–‡æ¡£

- [æ€§èƒ½ä¼˜åŒ–åŸç†](æ€§èƒ½ä¼˜åŒ–åŸç†.md) - å¦‚ä½•åˆ©ç”¨è¿™äº›æ¶æ„çŸ¥è¯†è¿›è¡Œä¼˜åŒ–
- [CUDA å­¦ä¹ æŒ‡å—](CUDAå­¦ä¹ æŒ‡å—.md) - ä»ç¼–ç¨‹è§’åº¦ç†è§£ CUDA
- [FAQ](FAQ.md) - å¸¸è§æ¶æ„ç›¸å…³é—®é¢˜

---

**ä¸‹ä¸€æ­¥**ï¼šé˜…è¯»ã€Šæ€§èƒ½ä¼˜åŒ–åŸç†ã€‹ï¼Œå­¦ä¹ å¦‚ä½•å°†æ¶æ„çŸ¥è¯†åº”ç”¨åˆ°å®é™…ä¼˜åŒ–ä¸­ï¼
