# CUDA ç¼–ç¨‹å®Œæ•´å­¦ä¹ æŒ‡å—

> æœ¬æŒ‡å—å°†å¸¦ä½ ä»é›¶å¼€å§‹å­¦ä¹  CUDA GPU ç¼–ç¨‹ï¼ŒåŒ…å«è¯¦ç»†çš„æ¦‚å¿µè§£é‡Šã€ä»£ç ç¤ºä¾‹å’Œå®è·µå»ºè®®ã€‚

## ç›®å½•

1. [CUDA åŸºç¡€æ¦‚å¿µ](#1-cuda-åŸºç¡€æ¦‚å¿µ)
2. [ç¬¬ä¸€ä¸ªç¨‹åºï¼šHello CUDA](#2-ç¬¬ä¸€ä¸ªç¨‹åºhello-cuda)
3. [CUDA æ ¸å‡½æ•°æ·±å…¥](#3-cuda-æ ¸å‡½æ•°æ·±å…¥)
4. [CUDA å†…å­˜ç®¡ç†](#4-cuda-å†…å­˜ç®¡ç†)
5. [å®Œæ•´é¡¹ç›®ï¼šå‘é‡åŠ æ³•](#5-å®Œæ•´é¡¹ç›®å‘é‡åŠ æ³•)
6. [å¸¸è§é—®é¢˜ä¸æŠ€å·§](#6-å¸¸è§é—®é¢˜ä¸æŠ€å·§)
7. [è¿›é˜¶å­¦ä¹ è·¯çº¿](#7-è¿›é˜¶å­¦ä¹ è·¯çº¿)

---

## 1. CUDA åŸºç¡€æ¦‚å¿µ

### 1.1 ä»€ä¹ˆæ˜¯ CUDAï¼Ÿ

CUDA (Compute Unified Device Architecture) æ˜¯ NVIDIA æ¨å‡ºçš„å¹¶è¡Œè®¡ç®—å¹³å°å’Œç¼–ç¨‹æ¨¡å‹ã€‚å®ƒå…è®¸ä½ ä½¿ç”¨ C/C++ ç¼–å†™åœ¨ GPU ä¸Šè¿è¡Œçš„ç¨‹åºã€‚

**ä¸ºä»€ä¹ˆè¦ç”¨ GPUï¼Ÿ**
- **CPU**: å°‘é‡æ ¸å¿ƒï¼ˆ4-16æ ¸ï¼‰ï¼Œæ¯ä¸ªæ ¸å¿ƒå¾ˆå¼ºå¤§ï¼Œé€‚åˆä¸²è¡Œä»»åŠ¡
- **GPU**: å¤§é‡æ ¸å¿ƒï¼ˆæ•°åƒä¸ªï¼‰ï¼Œæ¯ä¸ªæ ¸å¿ƒç®€å•ï¼Œé€‚åˆå¤§è§„æ¨¡å¹¶è¡Œä»»åŠ¡

### 1.2 æ ¸å¿ƒæ¦‚å¿µ

#### ğŸ”¹ ä¸»æœºï¼ˆHostï¼‰vs è®¾å¤‡ï¼ˆDeviceï¼‰
- **ä¸»æœºï¼ˆHostï¼‰**: CPU åŠå…¶å†…å­˜
- **è®¾å¤‡ï¼ˆDeviceï¼‰**: GPU åŠå…¶å†…å­˜

#### ğŸ”¹ çº¿ç¨‹ç»„ç»‡ç»“æ„

CUDA ä½¿ç”¨å±‚æ¬¡åŒ–çš„çº¿ç¨‹ç»„ç»‡ï¼š

```
Gridï¼ˆç½‘æ ¼ï¼‰
  â””â”€ Blockï¼ˆçº¿ç¨‹å—ï¼‰
       â””â”€ Threadï¼ˆçº¿ç¨‹ï¼‰
```

- **Threadï¼ˆçº¿ç¨‹ï¼‰**: æœ€å°æ‰§è¡Œå•å…ƒï¼Œæ‰§è¡Œæ ¸å‡½æ•°çš„ä»£ç 
- **Blockï¼ˆçº¿ç¨‹å—ï¼‰**: ä¸€ç»„çº¿ç¨‹ï¼Œå¯ä»¥å…±äº«å†…å­˜å’ŒåŒæ­¥
- **Gridï¼ˆç½‘æ ¼ï¼‰**: æ‰€æœ‰çº¿ç¨‹å—çš„é›†åˆ

**ç¤ºä¾‹**ï¼šå¦‚æœæœ‰ 2 ä¸ªå—ï¼Œæ¯å— 4 ä¸ªçº¿ç¨‹ï¼Œæ€»å…±å°±æœ‰ 8 ä¸ªçº¿ç¨‹åœ¨å¹¶è¡Œæ‰§è¡Œã€‚

#### ğŸ”¹ çº¿ç¨‹ç´¢å¼•

æ¯ä¸ªçº¿ç¨‹éœ€è¦çŸ¥é“è‡ªå·±æ˜¯è°ï¼Œé€šè¿‡å†…ç½®å˜é‡è·å–ï¼š

- `threadIdx.x/y/z`: çº¿ç¨‹åœ¨å—å†…çš„ç´¢å¼•
- `blockIdx.x/y/z`: å—åœ¨ç½‘æ ¼ä¸­çš„ç´¢å¼•
- `blockDim.x/y/z`: å—çš„å¤§å°ï¼ˆæ¯å—æœ‰å¤šå°‘çº¿ç¨‹ï¼‰
- `gridDim.x/y/z`: ç½‘æ ¼çš„å¤§å°ï¼ˆæœ‰å¤šå°‘å—ï¼‰

**è®¡ç®—å…¨å±€çº¿ç¨‹ ID**ï¼ˆä¸€ç»´æƒ…å†µï¼‰ï¼š
```cuda
int tid = threadIdx.x + blockIdx.x * blockDim.x;
```

#### ğŸ”¹ å‡½æ•°ç±»å‹é™å®šç¬¦

- `__global__`: æ ¸å‡½æ•°ï¼Œåœ¨ GPU ä¸Šæ‰§è¡Œï¼Œä» CPU è°ƒç”¨
- `__device__`: è®¾å¤‡å‡½æ•°ï¼Œåœ¨ GPU ä¸Šæ‰§è¡Œï¼Œä» GPU è°ƒç”¨
- `__host__`: ä¸»æœºå‡½æ•°ï¼Œåœ¨ CPU ä¸Šæ‰§è¡Œï¼ˆé»˜è®¤ï¼Œå¯çœç•¥ï¼‰

---

## 2. ç¬¬ä¸€ä¸ªç¨‹åºï¼šHello CUDA

### 2.1 ä»£ç æ–‡ä»¶ï¼š`hello_cuda.cu`

è¿™ä¸ªç¨‹åºæ¼”ç¤ºäº† CUDA çš„åŸºæœ¬ç»“æ„ï¼šè®©å¤šä¸ª GPU çº¿ç¨‹å¹¶è¡Œæ‰“å°æ¶ˆæ¯ã€‚

### 2.2 å®Œæ•´ä»£ç è§£æ

```cuda
#include <stdio.h>
#include <cuda_runtime.h>

// ============================================
// æ ¸å‡½æ•°å®šä¹‰
// ============================================
__global__ void helloFromGPU() {
    // è®¡ç®—å½“å‰çº¿ç¨‹çš„å…¨å±€ ID
    int tid = threadIdx.x + blockIdx.x * blockDim.x;
    printf("Hello from GPU! çº¿ç¨‹ ID: %d\n", tid);
}

int main() {
    // ============================================
    // 1. é…ç½®çº¿ç¨‹ç»„ç»‡
    // ============================================
    int numBlocks = 2;           // å¯åŠ¨ 2 ä¸ªçº¿ç¨‹å—
    int threadsPerBlock = 4;     // æ¯ä¸ªå—æœ‰ 4 ä¸ªçº¿ç¨‹
    // æ€»å…±ä¼šæœ‰ 2 Ã— 4 = 8 ä¸ªçº¿ç¨‹å¹¶è¡Œæ‰§è¡Œ

    // ============================================
    // 2. å¯åŠ¨æ ¸å‡½æ•°
    // ============================================
    // è¯­æ³•ï¼škernelName<<<blocks, threads>>>(å‚æ•°);
    helloFromGPU<<<numBlocks, threadsPerBlock>>>();

    // ============================================
    // 3. åŒæ­¥ç­‰å¾… GPU å®Œæˆ
    // ============================================
    cudaDeviceSynchronize();
    // ä¸ºä»€ä¹ˆéœ€è¦ï¼ŸGPU æ‰§è¡Œæ˜¯å¼‚æ­¥çš„ï¼ŒCPU ä¸ä¼šç­‰å¾…
    // è¿™ä¸ªå‡½æ•°å¼ºåˆ¶ CPU ç­‰å¾… GPU å®Œæˆæ‰€æœ‰æ“ä½œ

    // ============================================
    // 4. é”™è¯¯æ£€æŸ¥
    // ============================================
    cudaError_t error = cudaGetLastError();
    if (error != cudaSuccess) {
        printf("CUDA é”™è¯¯: %s\n", cudaGetErrorString(error));
        return 1;
    }

    return 0;
}
```

### 2.3 ç¼–è¯‘å’Œè¿è¡Œ

```bash
# ç¼–è¯‘
nvcc hello_cuda.cu -o hello_cuda

# è¿è¡Œ
./hello_cuda
```

### 2.4 é¢„æœŸè¾“å‡º

```
Hello from GPU! çº¿ç¨‹ ID: 0
Hello from GPU! çº¿ç¨‹ ID: 1
Hello from GPU! çº¿ç¨‹ ID: 2
Hello from GPU! çº¿ç¨‹ ID: 3
Hello from GPU! çº¿ç¨‹ ID: 4
Hello from GPU! çº¿ç¨‹ ID: 5
Hello from GPU! çº¿ç¨‹ ID: 6
Hello from GPU! çº¿ç¨‹ ID: 7
```

### 2.5 å…³é”®è¦ç‚¹

âœ… `__global__` æ ‡è®°æ ¸å‡½æ•°
âœ… `<<<blocks, threads>>>` é…ç½®å¹¶è¡Œåº¦
âœ… `cudaDeviceSynchronize()` ç­‰å¾… GPU å®Œæˆ
âœ… æ€»çº¿ç¨‹æ•° = blocks Ã— threads

### 2.6 ç»ƒä¹ 

1. ä¿®æ”¹ `numBlocks` å’Œ `threadsPerBlock`ï¼Œè§‚å¯Ÿçº¿ç¨‹ ID å˜åŒ–
2. å°è¯•è®©æ¯ä¸ªçº¿ç¨‹æ‰“å°è‡ªå·±çš„ `threadIdx.x` å’Œ `blockIdx.x`
3. æ€è€ƒï¼šå¦‚æœæœ‰ 100 ä¸ªä»»åŠ¡ï¼Œå¦‚ä½•é…ç½®çº¿ç¨‹ï¼Ÿ

---

## 3. CUDA æ ¸å‡½æ•°æ·±å…¥

### 3.1 ä»£ç æ–‡ä»¶ï¼š`kernel_basics.cu`

è¿™ä¸ªç¨‹åºå±•ç¤ºæ ¸å‡½æ•°çš„æ›´å¤šç‰¹æ€§ã€‚

### 3.2 è®¾å¤‡å‡½æ•°ç¤ºä¾‹

```cuda
// è®¾å¤‡å‡½æ•°ï¼šåªèƒ½åœ¨ GPU ä¸Šè¢«è°ƒç”¨
__device__ int square(int x) {
    return x * x;
}

__global__ void kernel1D() {
    int tid = threadIdx.x + blockIdx.x * blockDim.x;
    int squared = square(tid);  // è°ƒç”¨è®¾å¤‡å‡½æ•°
    printf("çº¿ç¨‹ %d: %d çš„å¹³æ–¹ = %d\n", tid, tid, squared);
}
```

**è¦ç‚¹**ï¼š
- `__device__` å‡½æ•°åªèƒ½è¢« `__global__` æˆ–å…¶ä»– `__device__` å‡½æ•°è°ƒç”¨
- ä¸èƒ½ä»ä¸»æœºä»£ç ç›´æ¥è°ƒç”¨

### 3.3 äºŒç»´çº¿ç¨‹é…ç½®

```cuda
__global__ void kernel2D() {
    int x = threadIdx.x + blockIdx.x * blockDim.x;
    int y = threadIdx.y + blockIdx.y * blockDim.y;
    printf("ä½ç½® (%d, %d)\n", x, y);
}

int main() {
    // ä½¿ç”¨ dim3 å®šä¹‰ 2D é…ç½®
    dim3 blocks(2, 2);      // 2Ã—2 = 4 ä¸ªå—
    dim3 threads(2, 2);     // æ¯å— 2Ã—2 = 4 ä¸ªçº¿ç¨‹
    kernel2D<<<blocks, threads>>>();
    cudaDeviceSynchronize();
}
```

**ä»€ä¹ˆæ—¶å€™ç”¨ 2D/3Dï¼Ÿ**
- å›¾åƒå¤„ç†ï¼š2Dï¼ˆå®½Ã—é«˜ï¼‰
- çŸ©é˜µè¿ç®—ï¼š2Dï¼ˆè¡ŒÃ—åˆ—ï¼‰
- 3D æ¨¡æ‹Ÿï¼š3Dï¼ˆxÃ—yÃ—zï¼‰

### 3.4 ä¼ é€’å‚æ•°

```cuda
__global__ void addValue(int *array, int value, int n) {
    int tid = threadIdx.x + blockIdx.x * blockDim.x;
    if (tid < n) {
        array[tid] += value;
    }
}
```

æ ¸å‡½æ•°å¯ä»¥æ¥æ”¶ï¼š
- âœ… åŸºæœ¬ç±»å‹ï¼ˆint, float, etc.ï¼‰
- âœ… æŒ‡é’ˆï¼ˆæŒ‡å‘ GPU å†…å­˜ï¼‰
- âœ… ç»“æ„ä½“ï¼ˆæŒ‰å€¼ä¼ é€’ï¼Œä¸è¦å¤ªå¤§ï¼‰
- âŒ ä¸èƒ½ä½¿ç”¨ C++ STLï¼ˆvector, string ç­‰ï¼‰

### 3.5 ç»ƒä¹ 

1. ç¼–å†™ä¸€ä¸ªæ ¸å‡½æ•°ï¼Œè®¡ç®—æ¯ä¸ªçº¿ç¨‹ ID çš„ç«‹æ–¹
2. å°è¯•åˆ›å»ºä¸€ä¸ª 3Ã—3 çš„çº¿ç¨‹ç½‘æ ¼
3. ä¿®æ”¹ä»£ç ï¼Œè®©æ ¸å‡½æ•°æ¥æ”¶ä¸€ä¸ªä¹˜æ•°å‚æ•°

---

## 4. CUDA å†…å­˜ç®¡ç†

### 4.1 å†…å­˜æ¨¡å‹

```
CPU å†…å­˜ï¼ˆä¸»æœºï¼‰          GPU å†…å­˜ï¼ˆè®¾å¤‡ï¼‰
    â†“                         â†“
[h_data]  â”€â”€â”€â”€å¤åˆ¶â”€â”€â”€â†’   [d_data]
           cudaMemcpy
[h_result] â†â”€â”€å¤åˆ¶â”€â”€â”€    [d_result]
```

**å…³é”®è§„åˆ™**ï¼š
- ä¸»æœºä¸èƒ½ç›´æ¥è®¿é—®è®¾å¤‡å†…å­˜
- è®¾å¤‡ä¸èƒ½ç›´æ¥è®¿é—®ä¸»æœºå†…å­˜
- å¿…é¡»æ˜¾å¼å¤åˆ¶æ•°æ®

### 4.2 å†…å­˜ç®¡ç†æ­¥éª¤

#### æ­¥éª¤ 1ï¼šåœ¨ä¸»æœºåˆ†é…å†…å­˜

```cuda
int N = 1000;
int size = N * sizeof(float);
float *h_data = (float*)malloc(size);  // CPU å†…å­˜
```

#### æ­¥éª¤ 2ï¼šåœ¨è®¾å¤‡åˆ†é…å†…å­˜

```cuda
float *d_data;
cudaMalloc((void**)&d_data, size);  // GPU å†…å­˜
```

**æ³¨æ„**ï¼š
- å‚æ•°æ˜¯æŒ‡é’ˆçš„æŒ‡é’ˆ `&d_data`
- è¿”å›å€¼æ˜¯é”™è¯¯ç ï¼Œéœ€è¦æ£€æŸ¥

#### æ­¥éª¤ 3ï¼šä¸»æœº â†’ è®¾å¤‡ å¤åˆ¶

```cuda
cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice);
```

å‚æ•°ï¼š
1. ç›®æ ‡åœ°å€ï¼ˆGPUï¼‰
2. æºåœ°å€ï¼ˆCPUï¼‰
3. å¤§å°ï¼ˆå­—èŠ‚ï¼‰
4. å¤åˆ¶æ–¹å‘

#### æ­¥éª¤ 4ï¼šæ‰§è¡Œæ ¸å‡½æ•°

```cuda
kernel<<<blocks, threads>>>(d_data, N);
cudaDeviceSynchronize();
```

#### æ­¥éª¤ 5ï¼šè®¾å¤‡ â†’ ä¸»æœº å¤åˆ¶

```cuda
cudaMemcpy(h_result, d_result, size, cudaMemcpyDeviceToHost);
```

#### æ­¥éª¤ 6ï¼šé‡Šæ”¾å†…å­˜

```cuda
cudaFree(d_data);    // é‡Šæ”¾ GPU å†…å­˜
free(h_data);        // é‡Šæ”¾ CPU å†…å­˜
```

### 4.3 é”™è¯¯æ£€æŸ¥æ¨¡å¼

```cuda
#define CHECK_CUDA(call) { \
    cudaError_t err = call; \
    if (err != cudaSuccess) { \
        printf("CUDA é”™è¯¯ %s:%d: %s\n", __FILE__, __LINE__, \
               cudaGetErrorString(err)); \
        exit(1); \
    } \
}

// ä½¿ç”¨æ–¹å¼
CHECK_CUDA(cudaMalloc(&d_data, size));
CHECK_CUDA(cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice));
```

### 4.4 ä»£ç æ–‡ä»¶ï¼š`memory_management.cu`

æŸ¥çœ‹å®Œæ•´ç¤ºä¾‹ï¼Œå®ƒæ¼”ç¤ºäº†ï¼š
- å®Œæ•´çš„å†…å­˜åˆ†é…ã€å¤åˆ¶ã€é‡Šæ”¾æµç¨‹
- é”™è¯¯æ£€æŸ¥
- æ•°æ®éªŒè¯

### 4.5 ç»ƒä¹ 

1. ä¿®æ”¹ç¨‹åºï¼Œå°†æ•°ç»„ä¹˜ä»¥ 3 è€Œä¸æ˜¯ 2
2. å¢åŠ æ•°ç»„å¤§å°åˆ° 1000ï¼Œè§‚å¯Ÿè¿è¡Œæƒ…å†µ
3. å°è¯•æ•…æ„å†™ä¸€ä¸ªé”™è¯¯ï¼ˆå¦‚å¤åˆ¶å¤§å°ä¸åŒ¹é…ï¼‰ï¼Œçœ‹é”™è¯¯æ£€æŸ¥å¦‚ä½•å·¥ä½œ

---

## 5. å®Œæ•´é¡¹ç›®ï¼šå‘é‡åŠ æ³•

### 5.1 é—®é¢˜æè¿°

è®¡ç®—ï¼š`C[i] = A[i] + B[i]`ï¼Œå¯¹äº i = 0 åˆ° N-1

### 5.2 CPU vs GPU å®ç°å¯¹æ¯”

#### CPU ç‰ˆæœ¬ï¼ˆä¸²è¡Œï¼‰

```cuda
void vectorAddCPU(float *a, float *b, float *c, int n) {
    for (int i = 0; i < n; i++) {  // é€ä¸ªè®¡ç®—
        c[i] = a[i] + b[i];
    }
}
```

æ—¶é—´å¤æ‚åº¦ï¼šO(n)

#### GPU ç‰ˆæœ¬ï¼ˆå¹¶è¡Œï¼‰

```cuda
__global__ void vectorAddGPU(float *a, float *b, float *c, int n) {
    int tid = threadIdx.x + blockIdx.x * blockDim.x;
    if (tid < n) {
        c[tid] = a[tid] + b[tid];  // æ‰€æœ‰çº¿ç¨‹åŒæ—¶è®¡ç®—
    }
}
```

æ—¶é—´å¤æ‚åº¦ï¼šO(1) ç†è®ºä¸Šï¼Œå®é™…å—ç¡¬ä»¶é™åˆ¶

### 5.3 ä¸ºä»€ä¹ˆéœ€è¦è¾¹ç•Œæ£€æŸ¥ï¼Ÿ

```cuda
if (tid < n) {
    c[tid] = a[tid] + b[tid];
}
```

**åŸå› **ï¼šçº¿ç¨‹æ•°å¾€å¾€ä¸èƒ½æ•´é™¤æ•°æ®é‡

ä¾‹å¦‚ï¼š
- æ•°æ®é‡ N = 1000
- threadsPerBlock = 256
- blocksPerGrid = (1000 + 256 - 1) / 256 = 4
- å®é™…å¯åŠ¨çº¿ç¨‹æ•° = 4 Ã— 256 = 1024

æœ‰ 24 ä¸ªå¤šä½™çº¿ç¨‹ï¼å¦‚æœä¸æ£€æŸ¥ï¼Œä¼šè®¿é—®è¶Šç•Œã€‚

### 5.4 æ€§èƒ½æµ‹é‡

#### CPU è®¡æ—¶

```cuda
#include <time.h>

clock_t start = clock();
vectorAddCPU(a, b, c, N);
clock_t end = clock();
double time_ms = ((double)(end - start)) / CLOCKS_PER_SEC * 1000;
```

#### GPU è®¡æ—¶ï¼ˆä½¿ç”¨ CUDA Eventï¼‰

```cuda
cudaEvent_t start, stop;
cudaEventCreate(&start);
cudaEventCreate(&stop);

cudaEventRecord(start);
// ... GPU æ“ä½œ ...
cudaEventRecord(stop);

cudaEventSynchronize(stop);
float time_ms;
cudaEventElapsedTime(&time_ms, start, stop);
```

### 5.5 æ€§èƒ½åˆ†æ

è¿è¡Œ `vector_add.cu` ä½ å¯èƒ½çœ‹åˆ° CPU æ›´å¿«ï¼Œä¸ºä»€ä¹ˆï¼Ÿ

#### GPU æ—¶é—´åˆ†è§£

```
æ€»æ—¶é—´ = æ•°æ®ä¼ è¾“æ—¶é—´ + è®¡ç®—æ—¶é—´
       = (Hâ†’D ä¼ è¾“) + æ ¸å‡½æ•°æ‰§è¡Œ + (Dâ†’H ä¼ è¾“)
```

**å¯¹äºå‘é‡åŠ æ³•**ï¼š
- è®¡ç®—ç®€å•ï¼ˆä¸€æ¬¡åŠ æ³•ï¼‰
- æ•°æ®ä¼ è¾“å¼€é”€å¤§
- é—®é¢˜è§„æ¨¡å°ï¼ˆ100ä¸‡å…ƒç´ ï¼‰

**GPU çš„ä¼˜åŠ¿åœºæ™¯**ï¼š
1. è®¡ç®—å¯†é›†ï¼ˆå¦‚çŸ©é˜µä¹˜æ³•ï¼‰
2. æ•°æ®é‡å¤§ï¼ˆæ•°åƒä¸‡ã€æ•°äº¿ï¼‰
3. å¯ä»¥é‡ç”¨æ•°æ®ï¼ˆå¤šæ¬¡è®¡ç®—ï¼Œå°‘æ¬¡ä¼ è¾“ï¼‰

### 5.6 ç»“æœéªŒè¯

```cuda
bool verifyResults(float *cpu_result, float *gpu_result, int n) {
    for (int i = 0; i < n; i++) {
        if (fabs(cpu_result[i] - gpu_result[i]) > 1e-5) {
            return false;  // ä¸åŒ¹é…
        }
    }
    return true;  // æ‰€æœ‰å…ƒç´ åŒ¹é…
}
```

**ä¸ºä»€ä¹ˆç”¨ `fabs` å’Œ `1e-5`ï¼Ÿ**
- æµ®ç‚¹æ•°è¿ç®—æœ‰ç²¾åº¦è¯¯å·®
- ä¸èƒ½ç›´æ¥ç”¨ `==` æ¯”è¾ƒ
- å…è®¸å°çš„è¯¯å·®èŒƒå›´

### 5.7 ç»ƒä¹ 

1. ä¿®æ”¹å‘é‡å¤§å°ï¼Œæµ‹è¯•ä¸åŒè§„æ¨¡ä¸‹çš„æ€§èƒ½
2. ä¿®æ”¹ä¸ºå‘é‡å‡æ³•æˆ–ä¹˜æ³•
3. å°è¯•ä¸åŒçš„ `threadsPerBlock` å€¼ï¼ˆ128, 256, 512ï¼‰ï¼Œæ¯”è¾ƒæ€§èƒ½

---

## 6. å¸¸è§é—®é¢˜ä¸æŠ€å·§

### 6.1 ç¼–è¯‘é”™è¯¯

**é—®é¢˜**ï¼š`nvcc: command not found`
**è§£å†³**ï¼šCUDA toolkit æœªå®‰è£…æˆ–æœªåŠ å…¥ PATH

**é—®é¢˜**ï¼š`undefined reference to cudaMalloc`
**è§£å†³**ï¼šæ–‡ä»¶åç¼€å¿…é¡»æ˜¯ `.cu` ä¸æ˜¯ `.c` æˆ– `.cpp`

### 6.2 è¿è¡Œæ—¶é”™è¯¯

**é—®é¢˜**ï¼šç¨‹åºå´©æºƒæ— è¾“å‡º
**è§£å†³**ï¼š
```cuda
// æ£€æŸ¥æ ¸å‡½æ•°é”™è¯¯
kernel<<<blocks, threads>>>();
cudaError_t err = cudaGetLastError();
if (err != cudaSuccess) {
    printf("Kernel é”™è¯¯: %s\n", cudaGetErrorString(err));
}
```

**é—®é¢˜**ï¼š`illegal memory access`
**è§£å†³**ï¼šæ£€æŸ¥æ•°ç»„è¶Šç•Œã€ç©ºæŒ‡é’ˆã€å†…å­˜æœªåˆ†é…

### 6.3 æ€§èƒ½ä¼˜åŒ–æŠ€å·§

#### é€‰æ‹©åˆé€‚çš„ threadsPerBlock

```cuda
// æ¨èå€¼ï¼š128, 256, 512
// å¿…é¡»æ˜¯ 32 çš„å€æ•°ï¼ˆwarp sizeï¼‰
int threadsPerBlock = 256;
int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;
```

#### å‡å°‘å†…å­˜ä¼ è¾“

```cuda
// âŒ ä¸å¥½ï¼šå¤šæ¬¡ä¼ è¾“
for (int i = 0; i < 100; i++) {
    cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice);
    kernel<<<blocks, threads>>>(d_data);
    cudaMemcpy(h_result, d_result, size, cudaMemcpyDeviceToHost);
}

// âœ… å¥½ï¼šåªä¼ è¾“ä¸€æ¬¡
cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice);
for (int i = 0; i < 100; i++) {
    kernel<<<blocks, threads>>>(d_data);
}
cudaMemcpy(h_result, d_result, size, cudaMemcpyDeviceToHost);
```

### 6.4 è°ƒè¯•æŠ€å·§

#### ä½¿ç”¨ printf è°ƒè¯•

```cuda
__global__ void debugKernel() {
    int tid = threadIdx.x + blockIdx.x * blockDim.x;
    if (tid == 0) {  // åªè®©ä¸€ä¸ªçº¿ç¨‹æ‰“å°
        printf("è°ƒè¯•ä¿¡æ¯\n");
    }
}
```

#### æ£€æŸ¥ GPU ä¿¡æ¯

```bash
nvidia-smi          # æŸ¥çœ‹ GPU çŠ¶æ€
nvcc --version      # æŸ¥çœ‹ CUDA ç‰ˆæœ¬
```

---

## 7. è¿›é˜¶å­¦ä¹ è·¯çº¿

### 7.1 ä¸‹ä¸€æ­¥å­¦ä¹ å†…å®¹

#### çº§åˆ« 2ï¼šä¼˜åŒ–æŠ€æœ¯
1. **å…±äº«å†…å­˜ï¼ˆShared Memoryï¼‰**
   - å—å†…çº¿ç¨‹å…±äº«çš„å¿«é€Ÿå†…å­˜
   - å‡å°‘å…¨å±€å†…å­˜è®¿é—®
   - çŸ©é˜µä¹˜æ³•ä¼˜åŒ–

2. **å†…å­˜åˆå¹¶ï¼ˆMemory Coalescingï¼‰**
   - ä¼˜åŒ–å…¨å±€å†…å­˜è®¿é—®æ¨¡å¼
   - æé«˜å¸¦å®½åˆ©ç”¨ç‡

3. **çº¿ç¨‹åŒæ­¥ï¼ˆSynchronizationï¼‰**
   - `__syncthreads()`
   - åŸå­æ“ä½œ

#### çº§åˆ« 3ï¼šé«˜çº§ç‰¹æ€§
1. **CUDA Streams**
   - å¹¶å‘æ‰§è¡Œå¤šä¸ªæ ¸å‡½æ•°
   - é‡å è®¡ç®—å’Œä¼ è¾“

2. **Unified Memory**
   - è‡ªåŠ¨ç®¡ç† CPU/GPU å†…å­˜
   - `cudaMallocManaged()`

3. **åŠ¨æ€å¹¶è¡Œ**
   - GPU ä¸Šå¯åŠ¨æ ¸å‡½æ•°

#### çº§åˆ« 4ï¼šå®é™…åº”ç”¨
1. **çŸ©é˜µä¹˜æ³•**
2. **å›¾åƒå¤„ç†**ï¼ˆæ»¤æ³¢ã€è¾¹ç¼˜æ£€æµ‹ï¼‰
3. **æ·±åº¦å­¦ä¹ **ï¼ˆä¸ PyTorch/TensorFlow é›†æˆï¼‰
4. **ç§‘å­¦è®¡ç®—**ï¼ˆFFT, éšæœºæ•°ç”Ÿæˆï¼‰

### 7.2 å­¦ä¹ èµ„æº

#### å®˜æ–¹æ–‡æ¡£
- CUDA C Programming Guide
- CUDA Best Practices Guide
- CUDA API Reference

#### æ¨èä¹¦ç±
- ã€ŠCUDA by Exampleã€‹ï¼ˆå…¥é—¨å‹å¥½ï¼‰
- ã€ŠProgramming Massively Parallel Processorsã€‹ï¼ˆæ·±å…¥ç†è§£ï¼‰

#### åœ¨çº¿èµ„æº
- NVIDIA Developer Blog
- CUDA Tutorial Series on YouTube
- GitHub CUDA Samples

### 7.3 å®è·µé¡¹ç›®å»ºè®®

1. **å›¾åƒæ¨¡ç³Š**ï¼šå®ç°é«˜æ–¯æ¨¡ç³Š
2. **çŸ©é˜µä¹˜æ³•**ï¼šæœ´ç´ ç‰ˆæœ¬ â†’ ä¼˜åŒ–ç‰ˆæœ¬
3. **N-body æ¨¡æ‹Ÿ**ï¼šç²’å­ç³»ç»Ÿ
4. **è’™ç‰¹å¡æ´›**ï¼šÏ€ å€¼ä¼°ç®—

---

## 8. è¿›é˜¶ä¸»é¢˜ï¼šå†…å­˜ä¼˜åŒ–

### 8.1 å…±äº«å†…å­˜

å…±äº«å†…å­˜æ˜¯å—å†…çº¿ç¨‹å…±äº«çš„å¿«é€Ÿå†…å­˜ï¼ˆçº¦ 100x å¿«äºå…¨å±€å†…å­˜ï¼‰ã€‚

```cuda
__global__ void sharedMemExample(float *input, float *output, int n) {
    // å£°æ˜å…±äº«å†…å­˜
    __shared__ float sdata[256];

    int tid = threadIdx.x;
    int gid = blockIdx.x * blockDim.x + threadIdx.x;

    // åŠ è½½æ•°æ®åˆ°å…±äº«å†…å­˜
    if (gid < n) {
        sdata[tid] = input[gid];
    }

    // åŒæ­¥ï¼šç¡®ä¿æ‰€æœ‰çº¿ç¨‹å®ŒæˆåŠ è½½
    __syncthreads();

    // ç°åœ¨å¯ä»¥è®¿é—®å…¶ä»–çº¿ç¨‹åŠ è½½çš„æ•°æ®
    // ä¾‹å¦‚ï¼šè®¿é—®é‚»å±…
    if (tid > 0 && gid < n) {
        output[gid] = sdata[tid] + sdata[tid - 1];
    }
}
```

**Bank Conflict é¿å…**ï¼š
```cuda
// æœ‰ bank conflict
__shared__ float tile[32][32];

// æ—  bank conflict (padding)
__shared__ float tile[32][32 + 1];
```

### 8.2 å†…å­˜åˆå¹¶è®¿é—®

**å¥½çš„è®¿é—®æ¨¡å¼**ï¼ˆè¿ç»­åœ°å€ï¼‰ï¼š
```cuda
// æ¯ä¸ªçº¿ç¨‹è®¿é—®è¿ç»­åœ°å€
int tid = threadIdx.x + blockIdx.x * blockDim.x;
float val = data[tid];  // åˆå¹¶è®¿é—®
```

**å·®çš„è®¿é—®æ¨¡å¼**ï¼ˆè·¨æ­¥è®¿é—®ï¼‰ï¼š
```cuda
// é—´éš”è®¿é—®å¯¼è‡´å¤šæ¬¡å†…å­˜äº‹åŠ¡
float val = data[tid * stride];  // éåˆå¹¶è®¿é—®
```

### 8.3 CUDA Streams

Streams å…è®¸å¹¶å‘æ‰§è¡Œæ“ä½œï¼š

```cuda
cudaStream_t stream1, stream2;
cudaStreamCreate(&stream1);
cudaStreamCreate(&stream2);

// å¼‚æ­¥æ“ä½œå¯ä»¥é‡å 
cudaMemcpyAsync(d_a, h_a, size, cudaMemcpyHostToDevice, stream1);
cudaMemcpyAsync(d_b, h_b, size, cudaMemcpyHostToDevice, stream2);

kernel<<<blocks, threads, 0, stream1>>>(d_a);
kernel<<<blocks, threads, 0, stream2>>>(d_b);

cudaStreamSynchronize(stream1);
cudaStreamSynchronize(stream2);

cudaStreamDestroy(stream1);
cudaStreamDestroy(stream2);
```

---

## 9. é«˜çº§ä¸»é¢˜æ¦‚è§ˆ

### 9.1 åä½œç»„ (Cooperative Groups)

æ›´çµæ´»çš„çº¿ç¨‹åŒæ­¥æœºåˆ¶ï¼š

```cuda
#include <cooperative_groups.h>
namespace cg = cooperative_groups;

__global__ void cooperativeKernel(float *data) {
    cg::thread_block block = cg::this_thread_block();
    cg::thread_block_tile<32> warp = cg::tiled_partition<32>(block);

    // Warp çº§åˆ«å½’çº¦
    float val = data[threadIdx.x];
    for (int offset = 16; offset > 0; offset /= 2) {
        val += warp.shfl_down(val, offset);
    }
}
```

### 9.2 CUDA Graphs

é¢„å®šä¹‰æ“ä½œåºåˆ—ï¼Œå‡å°‘å¯åŠ¨å¼€é”€ï¼š

```cuda
cudaGraph_t graph;
cudaGraphExec_t graphExec;
cudaStream_t stream;

// æ•è·æ“ä½œåºåˆ—
cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);
kernel1<<<...>>>(args);
kernel2<<<...>>>(args);
cudaStreamEndCapture(stream, &graph);

// å®ä¾‹åŒ–
cudaGraphInstantiate(&graphExec, graph, NULL, NULL, 0);

// å¤šæ¬¡æ‰§è¡Œ
for (int i = 0; i < 1000; i++) {
    cudaGraphLaunch(graphExec, stream);
}
```

### 9.3 æ··åˆç²¾åº¦è®¡ç®—

ä½¿ç”¨ FP16 æé«˜æ€§èƒ½ï¼š

```cuda
#include <cuda_fp16.h>

__global__ void fp16Kernel(half *output, const half *input, int n) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    if (tid < n) {
        // half2 æ“ä½œè·å¾— 2x åå
        half2 a = *reinterpret_cast<const half2*>(&input[tid*2]);
        half2 b = __hadd2(a, a);
        *reinterpret_cast<half2*>(&output[tid*2]) = b;
    }
}
```

### 9.4 å¤š GPU ç¼–ç¨‹

```cuda
int deviceCount;
cudaGetDeviceCount(&deviceCount);

for (int i = 0; i < deviceCount; i++) {
    cudaSetDevice(i);
    // åœ¨æ¯ä¸ª GPU ä¸Šåˆ†é…å’Œè®¡ç®—
    cudaMalloc(&d_data[i], size);
    kernel<<<blocks, threads>>>(d_data[i]);
}
```

---

## 10. æ·±åº¦å­¦ä¹ ç›¸å…³

### 10.1 å¸¸ç”¨æ“ä½œå®ç°

**GELU æ¿€æ´»å‡½æ•°**ï¼š
```cuda
__global__ void gelu(float *output, const float *input, int n) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    if (tid < n) {
        float x = input[tid];
        float cdf = 0.5f * (1.0f + tanhf(0.7978845608f *
                    (x + 0.044715f * x * x * x)));
        output[tid] = x * cdf;
    }
}
```

**LayerNorm**ï¼š
```cuda
// ç®€åŒ–ç‰ˆï¼šæ¯ä¸ª batch ä¸€ä¸ª block
__global__ void layerNorm(float *output, const float *input,
                          const float *gamma, const float *beta,
                          int hidden_size, float eps) {
    extern __shared__ float sdata[];

    // 1. è®¡ç®—å‡å€¼
    // 2. è®¡ç®—æ–¹å·®
    // 3. å½’ä¸€åŒ–: (x - mean) / sqrt(var + eps) * gamma + beta
}
```

### 10.2 PyTorch é›†æˆ

```python
# setup.py
from setuptools import setup
from torch.utils.cpp_extension import BuildExtension, CUDAExtension

setup(
    name='my_cuda_op',
    ext_modules=[
        CUDAExtension('my_cuda_op', [
            'my_kernel.cu',
        ])
    ],
    cmdclass={'build_ext': BuildExtension}
)
```

---

## é™„å½•ï¼šCUDA å‡½æ•°é€ŸæŸ¥

### å†…å­˜ç®¡ç†
```cuda
cudaMalloc(void **ptr, size_t size)
cudaFree(void *ptr)
cudaMemcpy(void *dst, void *src, size_t size, cudaMemcpyKind kind)
cudaMemset(void *ptr, int value, size_t size)
```

### è®¾å¤‡ç®¡ç†
```cuda
cudaDeviceSynchronize()       // ç­‰å¾… GPU å®Œæˆ
cudaGetLastError()            // è·å–æœ€åçš„é”™è¯¯
cudaGetDeviceCount(int *count)
cudaSetDevice(int device)
```

### äº‹ä»¶ç®¡ç†
```cuda
cudaEventCreate(cudaEvent_t *event)
cudaEventRecord(cudaEvent_t event)
cudaEventSynchronize(cudaEvent_t event)
cudaEventElapsedTime(float *ms, cudaEvent_t start, cudaEvent_t stop)
cudaEventDestroy(cudaEvent_t event)
```

### æ ¸å‡½æ•°å¯åŠ¨
```cuda
kernel<<<gridDim, blockDim, sharedMem, stream>>>(args);
// gridDim: å—çš„æ•°é‡ï¼ˆå¯ä»¥æ˜¯ int æˆ– dim3ï¼‰
// blockDim: æ¯å—çš„çº¿ç¨‹æ•°ï¼ˆå¯ä»¥æ˜¯ int æˆ– dim3ï¼‰
// sharedMem: åŠ¨æ€å…±äº«å†…å­˜å¤§å°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ 0ï¼‰
// stream: CUDA streamï¼ˆå¯é€‰ï¼Œé»˜è®¤ 0ï¼‰
```

---

## ç»“è¯­

æ­å–œä½ å®Œæˆäº† CUDA åŸºç¡€å­¦ä¹ ï¼

**è®°ä½çš„å…³é”®ç‚¹**ï¼š
1. âœ… ç†è§£ä¸»æœº/è®¾å¤‡å†…å­˜åˆ†ç¦»
2. âœ… æŒæ¡çº¿ç¨‹ç»„ç»‡å’Œç´¢å¼•
3. âœ… å§‹ç»ˆæ£€æŸ¥è¾¹ç•Œå’Œé”™è¯¯
4. âœ… æ€§èƒ½ä¸æ€»æ˜¯è¶Šå¿«è¶Šå¥½ï¼Œè¦è€ƒè™‘å¼€é”€
5. âœ… ä»ç®€å•å¼€å§‹ï¼Œé€æ­¥ä¼˜åŒ–

**ä¸‹ä¸€æ­¥**ï¼šé€‰æ‹©ä¸€ä¸ªæ„Ÿå…´è¶£çš„é¡¹ç›®å¼€å§‹å®è·µï¼

æœ‰é—®é¢˜éšæ—¶æé—®ï¼Œç¥å­¦ä¹ æ„‰å¿«ï¼ğŸš€
